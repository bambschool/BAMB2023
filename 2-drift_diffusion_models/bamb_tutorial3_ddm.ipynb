{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAMB! TUTORIAL 3: THE DRIFT-DIFFUSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running through Google Colab, run this cell to install pyddm\n",
    "!pip -q install pyddm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyddm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simulating the drift-diffusion model by hand\n",
    "We're going to simulate the drift-diffusion model in a variety of conditions and study of patterns of reaction times and responses that it produces, to develop some intutions on how the different parameters impact the behavior produced. The idea is to learning how the DDM works, but in practice, it is better to use an optimised library for simulating DDMs in your research.  In parts 2-4, we will learn to use one such library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Write a function to simulate the DDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ddm(drift_rate=.5, noise=.8, bound=1.2, dt=.01, T_dur=4):\n",
    "    \"\"\"\n",
    "    Simulate single run of discrete DDM (stores trajectory of decision variable)\n",
    "\n",
    "    [X, side, RT] = run_ddm(v, a, z, dt)\n",
    "    \n",
    "    Input:\n",
    "        drift_rate: drift rate\n",
    "        noise: standard deviation of noise\n",
    "        bound: the threshold(lower boundary corresponds to -a, upper boundary to a)\n",
    "        dt: time step for discretized version of dynamics\n",
    "        T_dur: total runtime, in seconds\n",
    "\n",
    "    Output:\n",
    "        X: vector with dynamics of the decision variable until hitting the boundary\n",
    "        side: +1 if DV hits the upper boundary, -1 if DV hits the lower boundary\n",
    "        RT: reaction time\n",
    "\n",
    "    \"\"\"\n",
    "    # FILL THIS IN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have written this function, use it simulate 5 trials and plot dynamics of the decision variable and bounds\n",
    "Use parameter values: drift = 0.5, bound = 1.2, and no non-decision-time.\n",
    "Use time step dt = 0.001 and a duration of 4 sec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bound = 1.2\n",
    "noise = .8\n",
    "drift_rate = .5\n",
    "T_dur = 4\n",
    "dt = .001\n",
    "\n",
    "# FILL THIS IN\n",
    "    \n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Decision variable')\n",
    "plt.ylim((-bound-.2, bound+.2))\n",
    "plt.xlim(0, T_dur+.2)\n",
    "plt.axhline(-bound, c='r')\n",
    "plt.axhline(bound, c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat with 500 trials.  Add transparency of 0.01 to the lines so that you can still see the density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL THIS IN\n",
    "    \n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Decision variable')\n",
    "plt.ylim((-bound-.2, bound+.2))\n",
    "plt.xlim((0, T_dur+.2))\n",
    "plt.axhline(bound, c='r')\n",
    "plt.axhline(-bound, c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice with transparency that you can see the density of particles which hit a given point.  We will come back to this in Part II."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Plot the RT distribution\n",
    "Run the DDM 10000 times.  We don't care about the trajectories here, but we do care about the RT and the choice that was made. Plot a histogram, separately for correct and incorrect responses.\n",
    "Use parameters: drift = 0.5, bound = 1.2, noise = 0.8, dt=.005, T_dur = 4.  Also include a non-decision time of 0.3 s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_trials = 10000\n",
    "drift_rate = .5\n",
    "bound = 1.2\n",
    "noise = .8\n",
    "dt = .005\n",
    "T_dur = 4\n",
    "non_decision_time = .3\n",
    "\n",
    "\n",
    "# FILL THIS IN \n",
    "# Put correct and error response times into the list \"correct_rts\" and \"error_rts\" to use the plotting code below.\n",
    "\n",
    "ax1 = plt.subplot(2,1,1)\n",
    "h = plt.hist(correct_rts, bins=np.arange(0, T_dur, dt*20))\n",
    "plt.title(\"Correct RT distribution\")\n",
    "plt.subplot(2,1,2, sharey=ax1)\n",
    "plt.hist(error_rts, bins=np.arange(0, T_dur, dt*20))\n",
    "plt.title(\"Error RT distribution\")\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Simulating the drift-diffusion model with PyDDM\n",
    "In practice, we generally want to perform simulations with a simulator instead of by hand.  This is because there are more efficient solutions than simulating individual trajectories.  For instance, many DDMs have closed-form mathematical expressions for the RT distribution.  For those that don't, it is possible to simulate the entire probability distribution of evolving particle density instead of individual particles one by one.\n",
    "\n",
    "You may find it useful in this section and later sections to consult the [PyDDM documentation](https://pyddm.readthedocs.io/en/stable/), especially the [cookbook](https://pyddm.readthedocs.io/en/stable/cookbook/index.html) and the [quick start guide](https://pyddm.readthedocs.io/en/stable/quickstart.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Simulate 10000 trials of the drift-diffusion model with PyDDM and plot the RT distribution\n",
    "Hint: You will want to create a PyDDM Model object, solve it, and then use the \"resample\" function on the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyddm\n",
    "\n",
    "# FILL THIS IN \n",
    "# Put correct and error response times into the list \"correct_rts\" and \"error_rts\" to use the plotting code below.\n",
    "\n",
    "ax1 = plt.subplot(2,1,1)\n",
    "plt.hist(correct_rts, bins=np.arange(0, T_dur, 20*.005))\n",
    "plt.title(\"Correct RT distribution\")\n",
    "plt.subplot(2,1,2, sharey=ax1)\n",
    "plt.hist(error_rts, bins=np.arange(0, T_dur, 20*.005))\n",
    "plt.title(\"Error RT distribution\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Simulate an infinite number of trials of the drift-diffusion model and plot the density\n",
    "Hint: Every \"solution\" object contains the full RT distribution as pdf(\"correct\") and pdf(\"error\"), so this should be easier than (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyddm\n",
    "\n",
    "# FILL THIS IN \n",
    "# Name your model \"m\" and put correct and error response times into the\n",
    "# lists \"correct_pdf\" and \"error_pdf\" to use the plotting code below.\n",
    "\n",
    "ax1 = plt.subplot(2,1,1)\n",
    "plt.plot(m.t_domain(), correct_pdf)\n",
    "plt.title(\"Correct RT distribution\")\n",
    "plt.subplot(2,1,2, sharey=ax1)\n",
    "plt.plot(m.t_domain(), error_pdf)\n",
    "plt.title(\"Error RT distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Use the following code to explore how the RT distribution depends on drift, noise, and bound\n",
    "Note: The \"Fittable\" object is a placeholder for a value which has not yet been fit to data.  We will see it again when we fit models to data below.\n",
    "Hint: Check the \"real-time\" checkbox once the model gui starts in order to update the plot as you drag the sliders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyddm\n",
    "from pyddm.plot import model_gui_jupyter\n",
    "\n",
    "# FILL THIS IN \n",
    "# Name your model \"m\" to use the plotting code below\n",
    "\n",
    "model_gui_jupyter(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Fitting the drift-diffusion model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Fit a simple DDM for a single subject\n",
    "We will fit the DDM to a non-human primate subject from [Roitman and Shadlen (2002)](https://www.jneurosci.org/content/22/21/9475) performing the random dot motion task.\n",
    "\n",
    "[Download data](https://pyddm.readthedocs.io/en/latest/_downloads/bcc1102d5b69c49dac52b49536b87240/roitman_rts.csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyddm\n",
    "import pyddm.plot\n",
    "import pandas\n",
    "\n",
    "#First, load the data we wish to use\n",
    "df_rt = pandas.read_csv(\"https://raw.githubusercontent.com/mwshinn/PyDDM/master/doc/downloads/roitman_rts.csv\")\n",
    "\n",
    "df_rt = df_rt[df_rt[\"monkey\"] == 1] # Only monkey 1\n",
    "\n",
    "# FILL THIS IN.\n",
    "# Create a PyDDM Sample named \"sample\" using the dataframe above.\n",
    "# Hint: see https://pyddm.readthedocs.io/en/latest/apidoc/model.html#module-pyddm.sample\n",
    "\n",
    "sample = pyddm.Sample.from_pandas_dataframe(df_rt, rt_column_name=\"rt\", correct_column_name=\"correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's fit a model that ignores the coherence.  It is probably not going to be a very good model, but it will show us how to fit a model in PyDDM.  We will fit the previous model we built.  This is the same model as before, but replacing the parameters to fit with a pyddm.Fittable placeholder.  We want to fit drift, noise, and non-decision time.  After that, use the model gui to visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL THIS IN.\n",
    "# Create a model named \"m\" to use the plotting code below\n",
    "\n",
    "pyddm.plot.model_gui_jupyter(model=m, sample=sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform the fit using the fit_adjust_model function.  Note that, as the name suggests, this changes the model by adjusting the model parameters, so the fitted parameters will be saved within our model.  Use LossRobustLikelihood as the loss function.  (We will see why later.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL THIS IN.\n",
    "# Name the model \"m\" to be compatible with the display and plotting code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show information about the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pyddm.display_model(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the model gui again, but this time, to visualise the fit that we just performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyddm.plot.model_gui_jupyter(model=m, sample=sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Fitting a coherence-dependent DDM to a single subject\n",
    "\n",
    "Notice how behaviour is different depending on the coherence of the random dot motion.  So, we need a Drift class which depends on the coherence condition.  For this, [here is an example from the PyDDM documentation](https://pyddm.readthedocs.io/en/latest/cookbook/driftnoise.html#drift-coh).  The bulk of this is implementing the get_drift function, which returns the drift value at a given time, position in space, and task conditions.  Here, we want the drift to be constant over time and space, but different for different task conditions.  So, we will use the \"conditions\" argument, and ignore the \"t\" and \"x\" arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DriftCoherence(pyddm.Drift):\n",
    "    name = # FILL THIS IN\n",
    "    required_conditions = # FILL THIS IN - this is from the Roitman-Shadlen dataset\n",
    "    required_parameters = # FILL THIS IN - we can name this parameter anything we want and use that name in get_drift\n",
    "    def get_drift(self, t, x, conditions, **kwargs):\n",
    "        # FILL THIS IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can construct the final model and fit it to data.  Create a Model object which uses your new Drift class and visualise it with your sample using pyddm.plot.model_gui_jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL THIS IN\n",
    "# Name the model \"m\" to be compatible with the plotting code below\n",
    "\n",
    "pyddm.plot.model_gui_jupyter(model=m, sample=sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, fit your model to data using fit_adjust_model.  Use RobustLikelihood as a loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL THIS IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) (optional) Plot the psychometric and chronometric functions\n",
    "The psychometric function shows the coherence/evidence on the x axis and the probability of a correct response on the y axis.  Likewise, the chronometric function shows the coherence/evidence on the x axis and the mean RT of correct responses on the y axis.\n",
    "\n",
    "Hint: PyDDM model Solutions (the output of m.solve()) have a prob(\"correct\") and prob(\"error\") methods, as well as mean_decision_time() function.\n",
    "\n",
    "Hint 2: PyDDM Samples have these methods too!  You might also want to use the \"subset\" method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL THIS IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Adding an explicit model of lapse rate\n",
    "What happens if the subject responds during the non-decision time?  Well, in theory, the model should give a likelihood of zero, and hence, a negative log likelihood of infinity.  (More generally, if there is even one \"outlier\" response at a time when the model predicts there should be none, this will have a large effect on the model.)  But when you look at our data, there are indeed a few responses during the non-decision time.  So why is the likelihood finite?\n",
    "\n",
    "It is finite because we have been cheating a bit.  Notice how when we fit the model previously, we used \"Robust Likelihood\".  What robust likelihood does is add a small constant offset to the likelihood of each point before taking the logarithm.  Is this best practice?  No, but lots of people still do it.  So let's properly model the lapse trials in addition to the actual trials.\n",
    "\n",
    "We do this using a mixture model.  We assume that X% of trials are generated by the DDM, and (100-X)% of trials are generated by some other process, for example, an evidence-independent probability distribution.  The two best choices to use for this are a uniform distribution, which assumes lapse trials are equally likely at any point in the trial, or an exponential distribution, which assumes lapse trials come from a poisson distribution (a flat hazard).\n",
    "\n",
    "We implement mixture models in PyDDM using an overlay.  However, since we are already using an overlay for non-decision time, we need to chain overlays together using pyddm.OverlayChain.  This can be used as follows:\n",
    "\n",
    "```\n",
    "overlay=pyddm.OverlayChain(overlays=[overlay1, overlay2]),\n",
    "```\n",
    "\n",
    "where \"overlay1\" and \"overlay2\" are overlays.  See [the PyDDM documentation](https://pyddm.readthedocs.io/en/latest/apidoc/dependences.html#module-ddm.models.overlay) for a list of all overlays included by default.  Once you are using a mixture model to account for lapse/outlier responses, you can change the loss function from \"LossRobustLikelihood\" to \"LossLikelihood\".\n",
    "\n",
    "Below, modify our model to use an error distribution with a uniform distribution.  Use a fittable mixture ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL THIS IN\n",
    "# Name the model \"m\" to be compatible with the plotting code below.\n",
    "\n",
    "pyddm.plot.model_gui_jupyter(model=m, sample=sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Generalized drift-diffusion models\n",
    "Generalized drift-diffusion models (GDDMs) allow going beyond the standard model parameters of the DDM.  Instead of drift, noise, and bound being fixed values, GDDMs allow them to be functions which may vary across time.  For example, this allows modelling tasks which have evidence that changes over time.  It also allows these to have complex, non-linear relationships with any number of task conditions and use any number of parameters.  For example, it is possible to model multisensory integration, with different streams of evidence contributing non-linearly to drift rate.  Furthermore, it also allows integration to be leaky (i.e. forgetting) or unstable (i.e. biasing early evidence), as well as representing an urgency signal (e.g. bounds which collapse over time).  There is evidence that these model properties are useful for modelling RTs in overtrained human or animal subjects.\n",
    "\n",
    "All of these exercises are optional and do not depend on each other - feel free to skip around and do those which are of greatest interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Collapsing boundaries\n",
    "Sometimes, especially in the case of overtrained animals, more evidence may be needed to make a decision earlier in the trial compared to later in the trial.  Construct, visualise, and fit a model with linearly collapsing boundaries to the data from (3).  It might take a bit longer to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL THIS IN\n",
    "# Name the model \"m\" to be compatible with the plotting code below.\n",
    "\n",
    "pyddm.plot.model_gui_jupyter(model=m, sample=sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyddm.fit_adjust_model(model=m, sample=sample, lossfunction=pyddm.LossRobustLikelihood, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Leaky integration\n",
    "Leaky integration occurs when the decision variable is constantly being pushed back to zero (a stable fixed point at zero).  This models forgetting, or alternatively, prioritising more recent evidence.  This is implemented in the model by making the drift rate depend on the position of the particle at any given time.  Construct and visualise a leaky integration model by modifying the DriftCoherence model above.  You do not need to fit it to data, since this may take a few minutes (and can be done the same way as all the above examples).  Note that leak can be negative: this is also called \"unstable integration\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DriftCoherenceLeaky(pyddm.Drift):\n",
    "    name = # FILL THIS IN\n",
    "    required_conditions = # FILL THIS IN\n",
    "    required_parameters = # FILL THIS IN\n",
    "    def get_drift(self, t, x, conditions, **kwargs):\n",
    "        # FILL THIS IN\n",
    "    \n",
    "m = pyddm.Model(drift=DriftCoherenceLeaky(drift=pyddm.Fittable(minval=-20, maxval=20), leak=pyddm.Fittable(minval=-2, maxval=2)),\n",
    "                noise=pyddm.NoiseConstant(noise=pyddm.Fittable(minval=.1, maxval=2)),\n",
    "                overlay=pyddm.OverlayNonDecision(nondectime=pyddm.Fittable(minval=0, maxval=.5)))\n",
    "\n",
    "pyddm.plot.model_gui_jupyter(model=m, sample=sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Side bias\n",
    "In our dataset, we also have information about which side the monkey chose to get the correct answer (\"trgchoice\" in the Roitman dataset, which has values \"1\" or \"2\").  Let's use a GDDM to implement a side bias.\n",
    "\n",
    "There are two common ways to implement a side bias.  The first is to assume that the biased side causes a constant offset bias on the drift rate.  So, in the 0% coherence condition, the drift rate will be towards the biased side.  Likewise, in a strong evidence condition, the drift rate will be stronger if it is on the same side as the bias.  This can be implemented by adding \"trgchoice\" as a \"required_condition\" to the drift rate and a parameter \"side_bias\" to describe the magnitude of the bias.  Then, when computing the drift function, add \"side_bias\" to the result if it is on the preferred side, and otherwise, subtract \"side_bias\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DriftCoherenceSideBias(pyddm.Drift):\n",
    "    name = # FILL THIS IN\n",
    "    required_conditions = # FILL THIS IN - Remember, we need two conditions now\n",
    "    required_parameters = # FILL THIS IN  - Remember, we need two parameters now\n",
    "    def get_drift(self, t, x, conditions, **kwargs):\n",
    "        # FILL THIS IN\n",
    "\n",
    "# FILL THIS IN\n",
    "# Create a model and name it \"m\" to be compatible with the plotting code below\n",
    "\n",
    "pyddm.plot.model_gui_jupyter(model=m, sample=sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other way is to assume that there is an offset in the starting position: instead of starting at zero, we start at some other point.  To do this, we need to implement a new InitialConditions, which takes the side as a condition and a parameter x0 of the magnitude of the bias.  Then, it returns a probability distribution where all the density is in a single point: the point x0 for one side, or -x0 for the other side.\n",
    "\n",
    "See the [PyDDM documentation](https://pyddm.readthedocs.io/en/stable/cookbook/initialconditions.html#biased-initial-conditions) for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICPointSideBias(pyddm.InitialCondition):\n",
    "    name = # FILL TIHS IN\n",
    "    required_parameters = # FILL THIS IN\n",
    "    required_conditions = # FILL THIS IN\n",
    "    def get_IC(self, t, x, dx, conditions):\n",
    "        # FILL THIS IN\n",
    "\n",
    "# FILL THIS IN\n",
    "# Create a model and name it \"m\" to be compatible with the plotting code below\n",
    "\n",
    "pyddm.plot.model_gui_jupyter(model=m, sample=sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Distributions of starting positions and non-decision time\n",
    "Suppose that, instead of starting at the position 0, the starting position of the integrator was pulled from a uniform distribution (where the size is a fittable parameter), and the non-decision time is pulled from a gamma distribution with fittable rate and shape parameters.\n",
    "\n",
    "Hint: PyDDM has built-in an OverlayNonDecisionGamma, as well an ICRange which may be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FILL THIS IN\n",
    "# Create a model and name it \"m\" to be compatible with the plotting code below\n",
    "\n",
    "pyddm.plot.model_gui_jupyter(model=m, sample=sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Evidence which changes over time\n",
    "Evidence is not always the same over time.  For instance, many tasks present discrete pulses of evidence.  Others may have evidence which is constantly fluctuating (e.g. changes in motion energy).\n",
    "\n",
    "To model this in PyDDM, we need to create a custom Drift object, as we did above.  But this time, the get_drift function should use the \"t\" function argument.\n",
    "\n",
    "Model a situation where we have two pulses of evidence, the first lasting from time 0.3 s to 0.6 s, and the second from 1.0 to 1.2 s.  Let the magnitude of each be given by the conditions \"pulse1\" and \"pulse2\".  Play with this model in the model_gui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyddm\n",
    "import pyddm.plot\n",
    "import numpy as np\n",
    "class DriftPulses(pyddm.Drift):\n",
    "    name = # FILL THIS IN\n",
    "    required_parameters = # FILL THIS IN\n",
    "    required_conditions = # FILL THIS IN\n",
    "    def get_drift(self, t, x, conditions, **_):\n",
    "        # FILL THIS IN\n",
    "\n",
    "# FILL THIS IN\n",
    "# Define a model using this Drift object and call it \"m\" to be compatible with the plotting code below.\n",
    "\n",
    "pyddm.plot.model_gui_jupyter(m, conditions={\"pulse1\": [0, .2, .4, .6], \"pulse2\": [0, .2, .4, .6]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
