{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "class Perceptron(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.W = nn.Parameter(torch.randn(output_size, input_size) * 0.01)\n",
    "        self.b = nn.Parameter(torch.zeros(output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.matmul(x, self.W.T) + self.b\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # Initialize weights and biases for the first Linear layer\n",
    "        self.W_ih = nn.Parameter(torch.randn(hidden_size, input_size) * 0.01)\n",
    "        self.b_ih = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "        # Initialize weights and biases for the second Linear layer\n",
    "        self.W_ho = nn.Parameter(torch.randn(output_size, hidden_size) * 0.01)\n",
    "        self.b_ho = nn.Parameter(torch.zeros(output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply the first linear layer with ReLU activation\n",
    "        h = torch.relu(torch.matmul(x, self.W_ih.T) + self.b_ih)\n",
    "\n",
    "        # Apply the second linear layer\n",
    "        x = torch.matmul(h, self.W_ho.T) + self.b_ho\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_linear_data(N=100, D=2):\n",
    "    X = np.random.randn(N, D)\n",
    "    X[:N//2, :] += 1\n",
    "    X[N//2:, :] -= 1\n",
    "    Y = np.concatenate((np.zeros(N//2), np.ones(N//2)))\n",
    "    X = torch.tensor(X, dtype=torch.float32)\n",
    "    Y = torch.tensor(Y, dtype=torch.long)\n",
    "    return X, Y\n",
    "\n",
    "def generate_xor_data():\n",
    "    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "    Y = np.array([0, 1, 1, 0], dtype=np.long)\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, X, Y, num_epochs=1000, print_interval=100):\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, Y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % print_interval == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "def evaluate_model(model, X, Y):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X)\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        accuracy = (predicted == Y).sum().item() / Y.size(0)\n",
    "        print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model, X, Y, title):\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                         np.arange(y_min, y_max, 0.01))\n",
    "    grid = torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        Z = model(grid)\n",
    "        Z = torch.sigmoid(Z.squeeze())\n",
    "        Z = (Z > 0.5).numpy()\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, alpha=0.8)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolors='k', marker='o')\n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Linearly Separate Two Clouds of Dots\n",
    "X_linear, Y_linear = generate_linear_data()\n",
    "input_size = 2\n",
    "output_size = 1\n",
    "\n",
    "# Perceptron\n",
    "model_perceptron = Perceptron(input_size, output_size)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model_perceptron.parameters(), lr=0.01)\n",
    "train_model(model_perceptron, criterion, optimizer, X_linear, Y_linear, num_epochs=1000, print_interval=100)\n",
    "plot_decision_boundary(model_perceptron, X_linear, Y_linear, 'Perceptron - Linear Data')\n",
    "\n",
    "# MLP\n",
    "hidden_size = 2\n",
    "model_mlp = MLP(input_size, hidden_size, output_size)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model_mlp.parameters(), lr=0.01)\n",
    "train_model(model_mlp, criterion, optimizer, X_linear, Y_linear, num_epochs=1000, print_interval=100)\n",
    "plot_decision_boundary(model_mlp, X_linear, Y_linear, 'MLP - Linear Data')\n",
    "\n",
    "# Task 2: XOR Task\n",
    "X_xor, Y_xor = generate_xor_data()\n",
    "\n",
    "# Perceptron\n",
    "model_perceptron = Perceptron(input_size, output_size)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model_perceptron.parameters(), lr=0.01)\n",
    "train_model(model_perceptron, criterion, optimizer, X_xor, Y_xor, num_epochs=10000, print_interval=1000)\n",
    "plot_decision_boundary(model_perceptron, X_xor, Y_xor, 'Perceptron - XOR Data')\n",
    "\n",
    "# MLP\n",
    "model_mlp = MLP(input_size, hidden_size, output_size)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model_mlp.parameters(), lr=0.1)\n",
    "train_model(model_mlp, criterion, optimizer, X_xor, Y_xor, num_epochs=10000, print_interval=1000)\n",
    "plot_decision_boundary(model_mlp, X_xor, Y_xor, 'MLP - XOR Data')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
